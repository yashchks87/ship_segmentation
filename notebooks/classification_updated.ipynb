{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow.keras.backend as K\n",
    "sys.path.append('../scripts/helper_functions_cv/tensorflow_helpers/')\n",
    "from save_weights_every_epoch import CallbackForSavingModelWeights\n",
    "from multiprocessing import Pool\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "import multiprocessing as mp\n",
    "sys.path.append('../scripts/')\n",
    "from find_bad_ones import find_bad_ones\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "allowed_gpus = [x for x in range(8)]\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "final_gpu_list = [gpus[x] for x in allowed_gpus]\n",
    "tf.config.set_visible_devices(final_gpu_list, \"GPU\")\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(REPLICAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../config_files/dev.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.pickle', 'rb') as handle:\n",
    "    updated_train_csv = pickle.load(handle)\n",
    "\n",
    "def split_datasets(data, test_size = 0.01):\n",
    "    train, test = train_test_split(data, test_size = test_size, random_state = 42) \n",
    "    train, val = train_test_split(train, test_size = test_size, random_state = 42)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(updated_train_csv)\n",
    "\n",
    "train_labels = train['class_labels'].values.tolist()\n",
    "computed = compute_class_weight(class_weight='balanced', classes=[0, 1], y=train_labels)\n",
    "class_weight_dict = {\n",
    "    0: computed[0],\n",
    "    1: computed[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_imgs(img, label, shape):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, size = shape)\n",
    "    img = img / 255\n",
    "    return img, label\n",
    "\n",
    "def get_data(data, shape = (256, 256), shuffle = True, repeat = True, batch = True, batch_size = 32):\n",
    "    imgs, labels = data['fixed_paths'].values.tolist(), data['class_labels'].values.tolist()\n",
    "    shapes = [shape for x in range(len(imgs))]\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((imgs, labels, shapes))\n",
    "    tensor = tensor.cache()\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if shuffle:\n",
    "        tensor = tensor.shuffle(8048 * 1)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        tensor = tensor.with_options(opt)\n",
    "    tensor = tensor.map(read_train_imgs)\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, shape):\n",
    "    with strategy.scope():\n",
    "        input_layer = tf.keras.Input(shape = shape)\n",
    "        construct = getattr(keras.applications, model_name)\n",
    "        mid_layer = construct(include_top = False, \n",
    "                            weights = None, \n",
    "                            pooling = 'avg')(input_layer)\n",
    "        last_layer = keras.layers.Dense(1, activation = 'sigmoid')(mid_layer)\n",
    "        model = keras.Model(input_layer, last_layer)\n",
    "    return model\n",
    "def compile_new_model(model):\n",
    "    with strategy.scope():\n",
    "        loss = keras.losses.BinaryCrossentropy(label_smoothing=0.05)\n",
    "        optimizer = keras.optimizers.SGD()\n",
    "        prec = keras.metrics.Precision(name = 'prec')\n",
    "        rec = keras.metrics.Recall(name = 'rec')\n",
    "        model.compile(\n",
    "            loss = loss,\n",
    "            optimizer = optimizer,\n",
    "            metrics = [prec, rec]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/ship_segmentation/TB/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['tb_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  6/184 [..............................] - ETA: 30s - loss: 0.9848 - prec: 0.2471 - rec: 0.2533WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1672s vs `on_train_batch_end` time: 0.4839s). Check your callbacks.\n",
      "184/184 [==============================] - 185s 259ms/step - loss: 0.6816 - prec: 0.3246 - rec: 0.1562 - val_loss: 0.5668 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00\n",
      "Epoch 2/30\n",
      "184/184 [==============================] - 39s 210ms/step - loss: 0.5519 - prec: 0.4758 - rec: 0.2385 - val_loss: 0.5562 - val_prec: 0.5000 - val_rec: 0.0023\n",
      "Epoch 3/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.5122 - prec: 0.5281 - rec: 0.2991 - val_loss: 0.5565 - val_prec: 0.6588 - val_rec: 0.1299\n",
      "Epoch 4/30\n",
      "184/184 [==============================] - 38s 208ms/step - loss: 0.4811 - prec: 0.5765 - rec: 0.3441 - val_loss: 0.4640 - val_prec: 0.5734 - val_rec: 0.3898\n",
      "Epoch 5/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.4670 - prec: 0.5966 - rec: 0.3887 - val_loss: 0.4673 - val_prec: 0.6364 - val_rec: 0.3573\n",
      "Epoch 6/30\n",
      "184/184 [==============================] - 39s 211ms/step - loss: 0.4503 - prec: 0.6151 - rec: 0.4162 - val_loss: 0.5010 - val_prec: 0.6859 - val_rec: 0.2483\n",
      "Epoch 7/30\n",
      "184/184 [==============================] - 39s 211ms/step - loss: 0.4388 - prec: 0.6310 - rec: 0.4385 - val_loss: 0.5594 - val_prec: 0.7045 - val_rec: 0.2877\n",
      "Epoch 8/30\n",
      "184/184 [==============================] - 39s 210ms/step - loss: 0.4301 - prec: 0.6425 - rec: 0.4592 - val_loss: 0.5487 - val_prec: 0.6852 - val_rec: 0.3434\n",
      "Epoch 9/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.4248 - prec: 0.6526 - rec: 0.4782 - val_loss: 0.4614 - val_prec: 0.6034 - val_rec: 0.5754\n",
      "Epoch 10/30\n",
      "184/184 [==============================] - 39s 209ms/step - loss: 0.4173 - prec: 0.6619 - rec: 0.4903 - val_loss: 0.4187 - val_prec: 0.7108 - val_rec: 0.4733\n",
      "Epoch 11/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.4096 - prec: 0.6761 - rec: 0.5040 - val_loss: 0.4519 - val_prec: 0.7259 - val_rec: 0.4548\n",
      "Epoch 12/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.4053 - prec: 0.6834 - rec: 0.5163 - val_loss: 0.4400 - val_prec: 0.7012 - val_rec: 0.5499\n",
      "Epoch 13/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.3994 - prec: 0.6930 - rec: 0.5253 - val_loss: 0.4608 - val_prec: 0.7681 - val_rec: 0.4687\n",
      "Epoch 14/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.3969 - prec: 0.6953 - rec: 0.5315 - val_loss: 0.4417 - val_prec: 0.6848 - val_rec: 0.5545\n",
      "Epoch 15/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.3906 - prec: 0.7078 - rec: 0.5476 - val_loss: 0.3977 - val_prec: 0.6658 - val_rec: 0.6288\n",
      "Epoch 16/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.3852 - prec: 0.7136 - rec: 0.5526 - val_loss: 0.3946 - val_prec: 0.7051 - val_rec: 0.5824\n",
      "Epoch 17/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.3808 - prec: 0.7220 - rec: 0.5645 - val_loss: 0.3951 - val_prec: 0.7692 - val_rec: 0.5104\n",
      "Epoch 18/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.3758 - prec: 0.7268 - rec: 0.5712 - val_loss: 0.3883 - val_prec: 0.7134 - val_rec: 0.5313\n",
      "Epoch 19/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.3731 - prec: 0.7323 - rec: 0.5765 - val_loss: 0.3894 - val_prec: 0.7734 - val_rec: 0.4988\n",
      "Epoch 20/30\n",
      "184/184 [==============================] - 39s 209ms/step - loss: 0.3704 - prec: 0.7371 - rec: 0.5821 - val_loss: 0.4166 - val_prec: 0.7107 - val_rec: 0.5244\n",
      "Epoch 21/30\n",
      "184/184 [==============================] - 38s 208ms/step - loss: 0.3659 - prec: 0.7409 - rec: 0.5890 - val_loss: 0.4550 - val_prec: 0.6127 - val_rec: 0.6937\n",
      "Epoch 22/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.3634 - prec: 0.7453 - rec: 0.5973 - val_loss: 0.3754 - val_prec: 0.7762 - val_rec: 0.5151\n",
      "Epoch 23/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.3592 - prec: 0.7532 - rec: 0.6040 - val_loss: 0.4096 - val_prec: 0.6667 - val_rec: 0.5800\n",
      "Epoch 24/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.3566 - prec: 0.7550 - rec: 0.6100 - val_loss: 0.3930 - val_prec: 0.6902 - val_rec: 0.5893\n",
      "Epoch 25/30\n",
      "184/184 [==============================] - 38s 208ms/step - loss: 0.3531 - prec: 0.7598 - rec: 0.6157 - val_loss: 0.3644 - val_prec: 0.7515 - val_rec: 0.5824\n",
      "Epoch 26/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.3496 - prec: 0.7690 - rec: 0.6230 - val_loss: 0.4061 - val_prec: 0.6296 - val_rec: 0.6705\n",
      "Epoch 27/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.3478 - prec: 0.7686 - rec: 0.6248 - val_loss: 0.4065 - val_prec: 0.7423 - val_rec: 0.5615\n",
      "Epoch 28/30\n",
      "184/184 [==============================] - 37s 203ms/step - loss: 0.3459 - prec: 0.7719 - rec: 0.6273 - val_loss: 0.3691 - val_prec: 0.7649 - val_rec: 0.5661\n",
      "Epoch 29/30\n",
      "184/184 [==============================] - 38s 205ms/step - loss: 0.3417 - prec: 0.7783 - rec: 0.6358 - val_loss: 0.3974 - val_prec: 0.6919 - val_rec: 0.5940\n",
      "Epoch 30/30\n",
      "184/184 [==============================] - 38s 205ms/step - loss: 0.3408 - prec: 0.7776 - rec: 0.6369 - val_loss: 0.3795 - val_prec: 0.7500 - val_rec: 0.6195\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "log_dir = f\"{os.environ['tb_path']}classification/res_50_baseline/\"\n",
    "if os.path.exists(log_dir) == False:\n",
    "    os.makedirs(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "batch_size = 128\n",
    "train_dataset = get_data(train, shape=(32, 32), batch_size = batch_size)\n",
    "val_dataset = get_data(val, shape=(32, 32), repeat = False, shuffle = False, batch_size=batch_size)\n",
    "model = create_model('ResNet50', (32, 32, 3))\n",
    "model = compile_new_model(model)\n",
    "model_hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    verbose = 1,\n",
    "    epochs = 30,\n",
    "    steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "    callbacks = [\n",
    "        tensorboard_callback,\n",
    "        weights_save\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  6/184 [..............................] - ETA: 29s - loss: 0.3327 - prec: 0.7977 - rec: 0.6529WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1617s vs `on_train_batch_end` time: 0.5167s). Check your callbacks.\n",
      "184/184 [==============================] - 172s 242ms/step - loss: 0.3373 - prec: 0.7850 - rec: 0.6445 - val_loss: 0.4081 - val_prec: 0.6700 - val_rec: 0.6311\n",
      "Epoch 2/30\n",
      "184/184 [==============================] - 39s 210ms/step - loss: 0.3330 - prec: 0.7888 - rec: 0.6492 - val_loss: 0.3788 - val_prec: 0.7194 - val_rec: 0.6009\n",
      "Epoch 3/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.3316 - prec: 0.7898 - rec: 0.6536 - val_loss: 0.3745 - val_prec: 0.7683 - val_rec: 0.6079\n",
      "Epoch 4/30\n",
      "184/184 [==============================] - 38s 208ms/step - loss: 0.3293 - prec: 0.7972 - rec: 0.6552 - val_loss: 0.3774 - val_prec: 0.7205 - val_rec: 0.6520\n",
      "Epoch 5/30\n",
      "184/184 [==============================] - 38s 208ms/step - loss: 0.3255 - prec: 0.7992 - rec: 0.6640 - val_loss: 0.4080 - val_prec: 0.7873 - val_rec: 0.4896\n",
      "Epoch 6/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.3234 - prec: 0.8017 - rec: 0.6666 - val_loss: 0.3849 - val_prec: 0.7147 - val_rec: 0.5986\n",
      "Epoch 7/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.3211 - prec: 0.8054 - rec: 0.6690 - val_loss: 0.3682 - val_prec: 0.7341 - val_rec: 0.6148\n",
      "Epoch 8/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.3204 - prec: 0.8070 - rec: 0.6730 - val_loss: 0.3874 - val_prec: 0.7697 - val_rec: 0.5661\n",
      "Epoch 9/30\n",
      "184/184 [==============================] - 38s 204ms/step - loss: 0.3163 - prec: 0.8107 - rec: 0.6803 - val_loss: 0.3918 - val_prec: 0.7874 - val_rec: 0.5499\n",
      "Epoch 10/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.3149 - prec: 0.8106 - rec: 0.6812 - val_loss: 0.4592 - val_prec: 0.7666 - val_rec: 0.5104\n",
      "Epoch 11/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.3130 - prec: 0.8154 - rec: 0.6833 - val_loss: 0.3635 - val_prec: 0.7591 - val_rec: 0.6288\n",
      "Epoch 12/30\n",
      "184/184 [==============================] - 38s 205ms/step - loss: 0.3095 - prec: 0.8195 - rec: 0.6891 - val_loss: 0.3965 - val_prec: 0.7601 - val_rec: 0.5661\n",
      "Epoch 13/30\n",
      "184/184 [==============================] - 39s 209ms/step - loss: 0.3071 - prec: 0.8238 - rec: 0.6922 - val_loss: 0.3925 - val_prec: 0.7185 - val_rec: 0.6218\n",
      "Epoch 14/30\n",
      "184/184 [==============================] - 38s 208ms/step - loss: 0.3059 - prec: 0.8267 - rec: 0.6963 - val_loss: 0.3997 - val_prec: 0.6889 - val_rec: 0.6218\n",
      "Epoch 15/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.3040 - prec: 0.8255 - rec: 0.7020 - val_loss: 0.3943 - val_prec: 0.7643 - val_rec: 0.5267\n",
      "Epoch 16/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.3014 - prec: 0.8293 - rec: 0.7036 - val_loss: 0.4309 - val_prec: 0.6008 - val_rec: 0.7332\n",
      "Epoch 17/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.2992 - prec: 0.8300 - rec: 0.7056 - val_loss: 0.3786 - val_prec: 0.7528 - val_rec: 0.6148\n",
      "Epoch 18/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.2978 - prec: 0.8342 - rec: 0.7094 - val_loss: 0.4079 - val_prec: 0.7508 - val_rec: 0.5592\n",
      "Epoch 19/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.2956 - prec: 0.8368 - rec: 0.7130 - val_loss: 0.4123 - val_prec: 0.6399 - val_rec: 0.6845\n",
      "Epoch 20/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.2936 - prec: 0.8396 - rec: 0.7161 - val_loss: 0.4331 - val_prec: 0.5757 - val_rec: 0.7146\n",
      "Epoch 21/30\n",
      "184/184 [==============================] - 38s 207ms/step - loss: 0.2925 - prec: 0.8409 - rec: 0.7185 - val_loss: 0.4124 - val_prec: 0.6245 - val_rec: 0.7796\n",
      "Epoch 22/30\n",
      "184/184 [==============================] - 38s 205ms/step - loss: 0.2914 - prec: 0.8442 - rec: 0.7232 - val_loss: 0.3641 - val_prec: 0.7948 - val_rec: 0.6381\n",
      "Epoch 23/30\n",
      "184/184 [==============================] - 38s 208ms/step - loss: 0.2883 - prec: 0.8461 - rec: 0.7249 - val_loss: 0.3692 - val_prec: 0.7574 - val_rec: 0.6520\n",
      "Epoch 24/30\n",
      "184/184 [==============================] - 38s 205ms/step - loss: 0.2866 - prec: 0.8457 - rec: 0.7273 - val_loss: 0.3834 - val_prec: 0.7193 - val_rec: 0.7077\n",
      "Epoch 25/30\n",
      "184/184 [==============================] - 37s 202ms/step - loss: 0.2845 - prec: 0.8498 - rec: 0.7328 - val_loss: 0.3927 - val_prec: 0.7018 - val_rec: 0.7100\n",
      "Epoch 26/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.2841 - prec: 0.8503 - rec: 0.7344 - val_loss: 0.4154 - val_prec: 0.7611 - val_rec: 0.5174\n",
      "Epoch 27/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.2833 - prec: 0.8506 - rec: 0.7351 - val_loss: 0.3839 - val_prec: 0.7337 - val_rec: 0.6520\n",
      "Epoch 28/30\n",
      "184/184 [==============================] - 38s 209ms/step - loss: 0.2812 - prec: 0.8533 - rec: 0.7390 - val_loss: 0.3844 - val_prec: 0.7500 - val_rec: 0.6265\n",
      "Epoch 29/30\n",
      "184/184 [==============================] - 39s 210ms/step - loss: 0.2791 - prec: 0.8578 - rec: 0.7420 - val_loss: 0.3844 - val_prec: 0.7117 - val_rec: 0.6473\n",
      "Epoch 30/30\n",
      "184/184 [==============================] - 38s 206ms/step - loss: 0.2773 - prec: 0.8606 - rec: 0.7452 - val_loss: 0.3801 - val_prec: 0.7097 - val_rec: 0.6636\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "log_dir = f\"{os.environ['tb_path']}classification/res_50_baseline_v1/\"\n",
    "if os.path.exists(log_dir) == False:\n",
    "    os.makedirs(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path, epoch_number=31)\n",
    "batch_size = 128\n",
    "train_dataset = get_data(train, shape=(32, 32), batch_size = batch_size)\n",
    "val_dataset = get_data(val, shape=(32, 32), repeat = False, shuffle = False, batch_size=batch_size)\n",
    "model = create_model('ResNet50', (32, 32, 3))\n",
    "model = compile_new_model(model)\n",
    "model.load_weights('/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline/30.h5')\n",
    "model_hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    verbose = 1,\n",
    "    epochs = 30,\n",
    "    steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "    callbacks = [\n",
    "        tensorboard_callback,\n",
    "        weights_save\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  6/184 [..............................] - ETA: 31s - loss: 0.6757 - prec: 0.2471 - rec: 0.1064WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1745s vs `on_train_batch_end` time: 0.5093s). Check your callbacks.\n",
      "184/184 [==============================] - 184s 261ms/step - loss: 0.6489 - prec: 0.3073 - rec: 0.0972 - val_loss: 0.5703 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00\n",
      "Epoch 2/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.5496 - prec: 0.4712 - rec: 0.1734 - val_loss: 0.5416 - val_prec: 0.2273 - val_rec: 0.0232\n",
      "Epoch 3/30\n",
      "184/184 [==============================] - 42s 227ms/step - loss: 0.5069 - prec: 0.5339 - rec: 0.2608 - val_loss: 0.5957 - val_prec: 0.4400 - val_rec: 0.0255\n",
      "Epoch 4/30\n",
      "184/184 [==============================] - 42s 228ms/step - loss: 0.4808 - prec: 0.5815 - rec: 0.3388 - val_loss: 0.6401 - val_prec: 0.6087 - val_rec: 0.0650\n",
      "Epoch 5/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.4645 - prec: 0.6023 - rec: 0.3890 - val_loss: 0.6708 - val_prec: 0.6724 - val_rec: 0.1810\n",
      "Epoch 6/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.4476 - prec: 0.6265 - rec: 0.4245 - val_loss: 0.4527 - val_prec: 0.5833 - val_rec: 0.4872\n",
      "Epoch 7/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.4353 - prec: 0.6498 - rec: 0.4501 - val_loss: 0.4795 - val_prec: 0.6102 - val_rec: 0.5012\n",
      "Epoch 8/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.4226 - prec: 0.6646 - rec: 0.4738 - val_loss: 0.4642 - val_prec: 0.6817 - val_rec: 0.4919\n",
      "Epoch 9/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.4125 - prec: 0.6847 - rec: 0.4947 - val_loss: 0.4210 - val_prec: 0.7280 - val_rec: 0.4223\n",
      "Epoch 10/30\n",
      "184/184 [==============================] - 41s 223ms/step - loss: 0.4028 - prec: 0.6951 - rec: 0.5097 - val_loss: 0.4499 - val_prec: 0.7449 - val_rec: 0.4200\n",
      "Epoch 11/30\n",
      "184/184 [==============================] - 41s 224ms/step - loss: 0.3934 - prec: 0.7155 - rec: 0.5275 - val_loss: 0.5171 - val_prec: 0.7892 - val_rec: 0.3735\n",
      "Epoch 12/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3880 - prec: 0.7283 - rec: 0.5420 - val_loss: 0.3957 - val_prec: 0.6477 - val_rec: 0.6613\n",
      "Epoch 13/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3784 - prec: 0.7407 - rec: 0.5530 - val_loss: 0.3847 - val_prec: 0.7597 - val_rec: 0.5429\n",
      "Epoch 14/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3750 - prec: 0.7487 - rec: 0.5623 - val_loss: 0.3779 - val_prec: 0.7445 - val_rec: 0.5476\n",
      "Epoch 15/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3671 - prec: 0.7563 - rec: 0.5756 - val_loss: 0.4156 - val_prec: 0.7155 - val_rec: 0.5777\n",
      "Epoch 16/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.3624 - prec: 0.7630 - rec: 0.5870 - val_loss: 0.3689 - val_prec: 0.8316 - val_rec: 0.5499\n",
      "Epoch 17/30\n",
      "184/184 [==============================] - 42s 228ms/step - loss: 0.3579 - prec: 0.7711 - rec: 0.5955 - val_loss: 0.3626 - val_prec: 0.8047 - val_rec: 0.5545\n",
      "Epoch 18/30\n",
      "184/184 [==============================] - 41s 222ms/step - loss: 0.3534 - prec: 0.7747 - rec: 0.6024 - val_loss: 0.3541 - val_prec: 0.7359 - val_rec: 0.6659\n",
      "Epoch 19/30\n",
      "184/184 [==============================] - 41s 222ms/step - loss: 0.3495 - prec: 0.7806 - rec: 0.6122 - val_loss: 0.3704 - val_prec: 0.7908 - val_rec: 0.5174\n",
      "Epoch 20/30\n",
      "184/184 [==============================] - 41s 224ms/step - loss: 0.3459 - prec: 0.7861 - rec: 0.6215 - val_loss: 0.3777 - val_prec: 0.8656 - val_rec: 0.5081\n",
      "Epoch 21/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3415 - prec: 0.7908 - rec: 0.6277 - val_loss: 0.3526 - val_prec: 0.7446 - val_rec: 0.6357\n",
      "Epoch 22/30\n",
      "184/184 [==============================] - 42s 227ms/step - loss: 0.3386 - prec: 0.7957 - rec: 0.6340 - val_loss: 0.3547 - val_prec: 0.8495 - val_rec: 0.5499\n",
      "Epoch 23/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3357 - prec: 0.7974 - rec: 0.6392 - val_loss: 0.3442 - val_prec: 0.8688 - val_rec: 0.5684\n",
      "Epoch 24/30\n",
      "184/184 [==============================] - 41s 221ms/step - loss: 0.3315 - prec: 0.8026 - rec: 0.6470 - val_loss: 0.3769 - val_prec: 0.8755 - val_rec: 0.5383\n",
      "Epoch 25/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3293 - prec: 0.8059 - rec: 0.6517 - val_loss: 0.3276 - val_prec: 0.8358 - val_rec: 0.6613\n",
      "Epoch 26/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3267 - prec: 0.8090 - rec: 0.6595 - val_loss: 0.3255 - val_prec: 0.8000 - val_rec: 0.6311\n",
      "Epoch 27/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3247 - prec: 0.8087 - rec: 0.6642 - val_loss: 0.3319 - val_prec: 0.8360 - val_rec: 0.6032\n",
      "Epoch 28/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.3204 - prec: 0.8151 - rec: 0.6666 - val_loss: 0.3438 - val_prec: 0.7890 - val_rec: 0.6334\n",
      "Epoch 29/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.3179 - prec: 0.8164 - rec: 0.6738 - val_loss: 0.3278 - val_prec: 0.8022 - val_rec: 0.6682\n",
      "Epoch 30/30\n",
      "184/184 [==============================] - 41s 221ms/step - loss: 0.3149 - prec: 0.8227 - rec: 0.6788 - val_loss: 0.3412 - val_prec: 0.7603 - val_rec: 0.6404\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "log_dir = f\"{os.environ['tb_path']}classification/res_50_baseline_64/\"\n",
    "if os.path.exists(log_dir) == False:\n",
    "    os.makedirs(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline_64/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "batch_size = 128\n",
    "train_dataset = get_data(train, shape=(64, 64), batch_size = batch_size)\n",
    "val_dataset = get_data(val, shape=(64, 64), repeat = False, shuffle = False, batch_size=batch_size)\n",
    "model = create_model('ResNet50', (64, 64, 3))\n",
    "model = compile_new_model(model)\n",
    "model_hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    verbose = 1,\n",
    "    epochs = 30,\n",
    "    steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "    callbacks = [\n",
    "        tensorboard_callback,\n",
    "        weights_save\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  6/184 [..............................] - ETA: 32s - loss: 0.3144 - prec: 0.8325 - rec: 0.6836WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1764s vs `on_train_batch_end` time: 0.4367s). Check your callbacks.\n",
      "184/184 [==============================] - 187s 260ms/step - loss: 0.3133 - prec: 0.8231 - rec: 0.6829 - val_loss: 0.3358 - val_prec: 0.7760 - val_rec: 0.6752\n",
      "Epoch 2/30\n",
      "184/184 [==============================] - 42s 230ms/step - loss: 0.3115 - prec: 0.8268 - rec: 0.6867 - val_loss: 0.3180 - val_prec: 0.8254 - val_rec: 0.6473\n",
      "Epoch 3/30\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.3085 - prec: 0.8269 - rec: 0.6893 - val_loss: 0.4022 - val_prec: 0.7473 - val_rec: 0.6311\n",
      "Epoch 4/30\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.3062 - prec: 0.8300 - rec: 0.6961 - val_loss: 0.3267 - val_prec: 0.8424 - val_rec: 0.6450\n",
      "Epoch 5/30\n",
      "184/184 [==============================] - 42s 227ms/step - loss: 0.3042 - prec: 0.8327 - rec: 0.7007 - val_loss: 0.3190 - val_prec: 0.7958 - val_rec: 0.6961\n",
      "Epoch 6/30\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.3026 - prec: 0.8322 - rec: 0.7064 - val_loss: 0.3314 - val_prec: 0.8553 - val_rec: 0.6311\n",
      "Epoch 7/30\n",
      "184/184 [==============================] - 42s 228ms/step - loss: 0.2987 - prec: 0.8387 - rec: 0.7088 - val_loss: 0.3789 - val_prec: 0.6569 - val_rec: 0.7819\n",
      "Epoch 8/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.2975 - prec: 0.8365 - rec: 0.7146 - val_loss: 0.3534 - val_prec: 0.7035 - val_rec: 0.7541\n",
      "Epoch 9/30\n",
      "184/184 [==============================] - 41s 223ms/step - loss: 0.2943 - prec: 0.8405 - rec: 0.7196 - val_loss: 0.3110 - val_prec: 0.8110 - val_rec: 0.6868\n",
      "Epoch 10/30\n",
      "184/184 [==============================] - 42s 229ms/step - loss: 0.2933 - prec: 0.8438 - rec: 0.7201 - val_loss: 0.3191 - val_prec: 0.8529 - val_rec: 0.6589\n",
      "Epoch 11/30\n",
      "184/184 [==============================] - 42s 227ms/step - loss: 0.2906 - prec: 0.8469 - rec: 0.7258 - val_loss: 0.3305 - val_prec: 0.8861 - val_rec: 0.5777\n",
      "Epoch 12/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.2886 - prec: 0.8469 - rec: 0.7284 - val_loss: 0.3172 - val_prec: 0.8309 - val_rec: 0.6613\n",
      "Epoch 13/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.2882 - prec: 0.8463 - rec: 0.7289 - val_loss: 0.3201 - val_prec: 0.8107 - val_rec: 0.6659\n",
      "Epoch 14/30\n",
      "184/184 [==============================] - 42s 227ms/step - loss: 0.2834 - prec: 0.8530 - rec: 0.7375 - val_loss: 0.3302 - val_prec: 0.7448 - val_rec: 0.7517\n",
      "Epoch 15/30\n",
      "184/184 [==============================] - 41s 224ms/step - loss: 0.2830 - prec: 0.8523 - rec: 0.7407 - val_loss: 0.3254 - val_prec: 0.8433 - val_rec: 0.6241\n",
      "Epoch 16/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.2808 - prec: 0.8581 - rec: 0.7425 - val_loss: 0.3115 - val_prec: 0.8395 - val_rec: 0.6798\n",
      "Epoch 17/30\n",
      "184/184 [==============================] - 42s 228ms/step - loss: 0.2783 - prec: 0.8587 - rec: 0.7486 - val_loss: 0.3233 - val_prec: 0.7488 - val_rec: 0.7541\n",
      "Epoch 18/30\n",
      "184/184 [==============================] - 42s 227ms/step - loss: 0.2773 - prec: 0.8594 - rec: 0.7505 - val_loss: 0.3538 - val_prec: 0.8671 - val_rec: 0.6659\n",
      "Epoch 19/30\n",
      "184/184 [==============================] - 41s 224ms/step - loss: 0.2750 - prec: 0.8622 - rec: 0.7545 - val_loss: 0.3177 - val_prec: 0.7756 - val_rec: 0.7216\n",
      "Epoch 20/30\n",
      "184/184 [==============================] - 41s 224ms/step - loss: 0.2716 - prec: 0.8646 - rec: 0.7594 - val_loss: 0.3093 - val_prec: 0.8429 - val_rec: 0.6845\n",
      "Epoch 21/30\n",
      "184/184 [==============================] - 41s 223ms/step - loss: 0.2708 - prec: 0.8676 - rec: 0.7611 - val_loss: 0.3028 - val_prec: 0.8146 - val_rec: 0.7239\n",
      "Epoch 22/30\n",
      "184/184 [==============================] - 42s 227ms/step - loss: 0.2688 - prec: 0.8686 - rec: 0.7658 - val_loss: 0.3732 - val_prec: 0.8922 - val_rec: 0.5568\n",
      "Epoch 23/30\n",
      "184/184 [==============================] - 41s 224ms/step - loss: 0.2664 - prec: 0.8707 - rec: 0.7683 - val_loss: 0.3064 - val_prec: 0.7939 - val_rec: 0.7239\n",
      "Epoch 24/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.2644 - prec: 0.8741 - rec: 0.7725 - val_loss: 0.3698 - val_prec: 0.6883 - val_rec: 0.7633\n",
      "Epoch 25/30\n",
      "184/184 [==============================] - 41s 224ms/step - loss: 0.2629 - prec: 0.8750 - rec: 0.7757 - val_loss: 0.3235 - val_prec: 0.8097 - val_rec: 0.6613\n",
      "Epoch 26/30\n",
      "184/184 [==============================] - 41s 225ms/step - loss: 0.2604 - prec: 0.8790 - rec: 0.7794 - val_loss: 0.3622 - val_prec: 0.7359 - val_rec: 0.6659\n",
      "Epoch 27/30\n",
      "184/184 [==============================] - 42s 226ms/step - loss: 0.2595 - prec: 0.8805 - rec: 0.7828 - val_loss: 0.3580 - val_prec: 0.8585 - val_rec: 0.6334\n",
      "Epoch 28/30\n",
      "184/184 [==============================] - 41s 223ms/step - loss: 0.2573 - prec: 0.8817 - rec: 0.7835 - val_loss: 0.3078 - val_prec: 0.8550 - val_rec: 0.6705\n",
      "Epoch 29/30\n",
      "184/184 [==============================] - 41s 224ms/step - loss: 0.2528 - prec: 0.8870 - rec: 0.7914 - val_loss: 0.3280 - val_prec: 0.8571 - val_rec: 0.6682\n",
      "Epoch 30/30\n",
      "184/184 [==============================] - 41s 221ms/step - loss: 0.2520 - prec: 0.8871 - rec: 0.7955 - val_loss: 0.3017 - val_prec: 0.8529 - val_rec: 0.7262\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "log_dir = f\"{os.environ['tb_path']}classification/res_50_baseline_64_v1/\"\n",
    "if os.path.exists(log_dir) == False:\n",
    "    os.makedirs(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline_64/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path, epoch_number=31)\n",
    "batch_size = 128\n",
    "train_dataset = get_data(train, shape=(64, 64), batch_size = batch_size)\n",
    "val_dataset = get_data(val, shape=(64, 64), repeat = False, shuffle = False, batch_size=batch_size)\n",
    "model = create_model('ResNet50', (64, 64, 3))\n",
    "model = compile_new_model(model)\n",
    "model.load_weights('/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline_64/30.h5')\n",
    "model_hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    verbose = 1,\n",
    "    epochs = 30,\n",
    "    steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "    callbacks = [\n",
    "        tensorboard_callback,\n",
    "        weights_save\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/184 [..............................] - ETA: 39s - loss: 1.1728 - prec: 0.2396 - rec: 0.2001WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2162s vs `on_train_batch_end` time: 0.4461s). Check your callbacks.\n",
      "184/184 [==============================] - 187s 297ms/step - loss: 0.6092 - prec: 0.4112 - rec: 0.1381 - val_loss: 0.6192 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00\n",
      "Epoch 2/30\n",
      "184/184 [==============================] - 52s 283ms/step - loss: 0.5211 - prec: 0.5183 - rec: 0.2663 - val_loss: 0.5579 - val_prec: 0.5128 - val_rec: 0.0464\n",
      "Epoch 3/30\n",
      "184/184 [==============================] - 52s 283ms/step - loss: 0.4843 - prec: 0.5614 - rec: 0.3410 - val_loss: 0.6362 - val_prec: 0.4049 - val_rec: 0.6566\n",
      "Epoch 4/30\n",
      "184/184 [==============================] - 52s 282ms/step - loss: 0.4479 - prec: 0.6240 - rec: 0.4201 - val_loss: 0.5203 - val_prec: 0.6974 - val_rec: 0.2459\n",
      "Epoch 5/30\n",
      "184/184 [==============================] - 52s 283ms/step - loss: 0.4247 - prec: 0.6740 - rec: 0.4781 - val_loss: 0.5731 - val_prec: 0.5862 - val_rec: 0.4733\n",
      "Epoch 6/30\n",
      "184/184 [==============================] - 52s 282ms/step - loss: 0.3943 - prec: 0.7252 - rec: 0.5182 - val_loss: 0.4434 - val_prec: 0.6134 - val_rec: 0.6148\n",
      "Epoch 7/30\n",
      "184/184 [==============================] - 51s 280ms/step - loss: 0.3785 - prec: 0.7518 - rec: 0.5491 - val_loss: 0.4495 - val_prec: 0.5991 - val_rec: 0.6102\n",
      "Epoch 8/30\n",
      "184/184 [==============================] - 52s 280ms/step - loss: 0.3616 - prec: 0.7771 - rec: 0.5764 - val_loss: 0.3786 - val_prec: 0.7032 - val_rec: 0.6543\n",
      "Epoch 9/30\n",
      "184/184 [==============================] - 51s 279ms/step - loss: 0.3482 - prec: 0.7962 - rec: 0.6026 - val_loss: 0.4761 - val_prec: 0.5615 - val_rec: 0.8051\n",
      "Epoch 10/30\n",
      "184/184 [==============================] - 51s 278ms/step - loss: 0.3379 - prec: 0.8093 - rec: 0.6258 - val_loss: 0.4146 - val_prec: 0.9357 - val_rec: 0.3712\n",
      "Epoch 11/30\n",
      "184/184 [==============================] - 51s 279ms/step - loss: 0.3265 - prec: 0.8231 - rec: 0.6478 - val_loss: 0.3275 - val_prec: 0.8276 - val_rec: 0.6682\n",
      "Epoch 12/30\n",
      "184/184 [==============================] - 52s 283ms/step - loss: 0.3168 - prec: 0.8325 - rec: 0.6671 - val_loss: 0.3272 - val_prec: 0.8624 - val_rec: 0.6543\n",
      "Epoch 13/30\n",
      "184/184 [==============================] - 52s 283ms/step - loss: 0.3065 - prec: 0.8429 - rec: 0.6884 - val_loss: 0.3595 - val_prec: 0.8690 - val_rec: 0.6311\n",
      "Epoch 14/30\n",
      "184/184 [==============================] - 52s 281ms/step - loss: 0.3018 - prec: 0.8447 - rec: 0.7018 - val_loss: 0.3219 - val_prec: 0.7657 - val_rec: 0.7053\n",
      "Epoch 15/30\n",
      "184/184 [==============================] - 52s 280ms/step - loss: 0.2942 - prec: 0.8537 - rec: 0.7157 - val_loss: 0.3397 - val_prec: 0.8338 - val_rec: 0.6752\n",
      "Epoch 16/30\n",
      "184/184 [==============================] - 52s 282ms/step - loss: 0.2861 - prec: 0.8591 - rec: 0.7300 - val_loss: 0.2991 - val_prec: 0.8645 - val_rec: 0.6659\n",
      "Epoch 17/30\n",
      "184/184 [==============================] - 51s 279ms/step - loss: 0.2822 - prec: 0.8638 - rec: 0.7409 - val_loss: 0.2976 - val_prec: 0.8736 - val_rec: 0.7378\n",
      "Epoch 18/30\n",
      "184/184 [==============================] - 52s 280ms/step - loss: 0.2765 - prec: 0.8664 - rec: 0.7484 - val_loss: 0.3108 - val_prec: 0.8082 - val_rec: 0.7819\n",
      "Epoch 19/30\n",
      "184/184 [==============================] - 52s 280ms/step - loss: 0.2725 - prec: 0.8688 - rec: 0.7592 - val_loss: 0.2972 - val_prec: 0.8622 - val_rec: 0.7401\n",
      "Epoch 20/30\n",
      "184/184 [==============================] - 51s 279ms/step - loss: 0.2688 - prec: 0.8734 - rec: 0.7665 - val_loss: 0.2846 - val_prec: 0.8964 - val_rec: 0.7425\n",
      "Epoch 21/30\n",
      "184/184 [==============================] - 51s 280ms/step - loss: 0.2649 - prec: 0.8763 - rec: 0.7723 - val_loss: 0.2867 - val_prec: 0.8118 - val_rec: 0.8306\n",
      "Epoch 22/30\n",
      "184/184 [==============================] - 52s 281ms/step - loss: 0.2609 - prec: 0.8798 - rec: 0.7809 - val_loss: 0.2827 - val_prec: 0.8362 - val_rec: 0.7819\n",
      "Epoch 23/30\n",
      "184/184 [==============================] - 52s 280ms/step - loss: 0.2574 - prec: 0.8815 - rec: 0.7844 - val_loss: 0.3120 - val_prec: 0.8663 - val_rec: 0.6914\n",
      "Epoch 24/30\n",
      "184/184 [==============================] - 52s 280ms/step - loss: 0.2548 - prec: 0.8833 - rec: 0.7931 - val_loss: 0.2718 - val_prec: 0.8564 - val_rec: 0.7889\n",
      "Epoch 25/30\n",
      "184/184 [==============================] - 51s 279ms/step - loss: 0.2524 - prec: 0.8836 - rec: 0.7957 - val_loss: 0.2554 - val_prec: 0.9005 - val_rec: 0.7773\n",
      "Epoch 26/30\n",
      "184/184 [==============================] - 52s 282ms/step - loss: 0.2496 - prec: 0.8870 - rec: 0.8019 - val_loss: 0.2552 - val_prec: 0.8645 - val_rec: 0.8144\n",
      "Epoch 27/30\n",
      "184/184 [==============================] - 52s 283ms/step - loss: 0.2466 - prec: 0.8890 - rec: 0.8071 - val_loss: 0.2820 - val_prec: 0.9159 - val_rec: 0.7332\n",
      "Epoch 28/30\n",
      "184/184 [==============================] - 52s 280ms/step - loss: 0.2445 - prec: 0.8919 - rec: 0.8085 - val_loss: 0.2675 - val_prec: 0.8416 - val_rec: 0.8260\n",
      "Epoch 29/30\n",
      "184/184 [==============================] - 52s 282ms/step - loss: 0.2427 - prec: 0.8917 - rec: 0.8136 - val_loss: 0.2537 - val_prec: 0.8947 - val_rec: 0.7889\n",
      "Epoch 30/30\n",
      "121/184 [==================>...........] - ETA: 16s - loss: 0.2393 - prec: 0.8960 - rec: 0.8179"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "log_dir = f\"{os.environ['tb_path']}classification/res_50_baseline_128/\"\n",
    "if os.path.exists(log_dir) == False:\n",
    "    os.makedirs(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline_128/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "batch_size = 128\n",
    "train_dataset = get_data(train, shape=(128, 128), batch_size = batch_size)\n",
    "val_dataset = get_data(val, shape=(128, 128), repeat = False, shuffle = False, batch_size=batch_size)\n",
    "model = create_model('ResNet50', (128, 128, 3))\n",
    "model = compile_new_model(model)\n",
    "model_hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    verbose = 1,\n",
    "    epochs = 30,\n",
    "    steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "    callbacks = [\n",
    "        tensorboard_callback,\n",
    "        weights_save\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "log_dir = f\"{os.environ['tb_path']}classification/res_50_baseline_128_v1/\"\n",
    "if os.path.exists(log_dir) == False:\n",
    "    os.makedirs(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline_128/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path, epoch_number = 31)\n",
    "batch_size = 128\n",
    "train_dataset = get_data(train, shape=(128, 128), batch_size = batch_size)\n",
    "val_dataset = get_data(val, shape=(128, 128), repeat = False, shuffle = False, batch_size=batch_size)\n",
    "model = create_model('ResNet50', (128, 128, 3))\n",
    "model = compile_new_model(model)\n",
    "model.load_weights('/home/ubuntu/ml-data-training/ship_seg_weights/classification/res_50_baseline_128/30.h5')\n",
    "model_hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    verbose = 1,\n",
    "    epochs = 30,\n",
    "    steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "    callbacks = [\n",
    "        tensorboard_callback,\n",
    "        weights_save\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "log_dir = f\"{os.environ['tb_path']}classification/efb0_baseline_128/\"\n",
    "if os.path.exists(log_dir) == False:\n",
    "    os.makedirs(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'/home/ubuntu/ml-data-training/ship_seg_weights/classification/efb0_baseline_128/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path, epoch_number = 31)\n",
    "batch_size = 128\n",
    "train_dataset = get_data(train, shape=(128, 128), batch_size = batch_size)\n",
    "val_dataset = get_data(val, shape=(128, 128), repeat = False, shuffle = False, batch_size=batch_size)\n",
    "model = create_model('EfficientNetB0', (128, 128, 3))\n",
    "model = compile_new_model(model)\n",
    "model_hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    verbose = 1,\n",
    "    epochs = 30,\n",
    "    steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "    callbacks = [\n",
    "        tensorboard_callback,\n",
    "        weights_save\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
