{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import PIL\n",
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "import glob\n",
    "sys.path.append('../scripts/helper_functions_cv/tensorflow_helpers/')\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "import multiprocessing as mp\n",
    "from save_weights_every_epoch import CallbackForSavingModelWeights\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv('../../ml-data-training/ship_segmentation_data/train_ship_segmentations_v2.csv')\n",
    "csv_file = csv_file.groupby('ImageId')['EncodedPixels'].apply(list).reset_index()\n",
    "image_ids, pixels = csv_file['ImageId'].values.tolist(), csv_file['EncodedPixels'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file['fixed_inputs'] = csv_file['ImageId'].apply(lambda x: '../../ml-data-training/ship_segmentation_data/train_v2/' + x)\n",
    "csv_file['mask_paths'] = csv_file['ImageId'].apply(lambda x: '../../ml-data-training/ship_segmentation_data/masks_v1/train/' + x.split('.')[0] + '.' + 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in csv_file['fixed_inputs'].values.tolist():\n",
    "#     if os.path.exists(x) == False:\n",
    "#         print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in csv_file['mask_paths'].values.tolist():\n",
    "#     if os.path.exists(x) == False:\n",
    "#         print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = csv_file[csv_file['fixed_inputs'] != '../../ml-data-training/ship_segmentation_data/train_v2/6384c3e78.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "allowed_gpus = [0]\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "final_gpu_list = [gpus[x] for x in allowed_gpus]\n",
    "tf.config.set_visible_devices(final_gpu_list, \"GPU\")\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(REPLICAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../config_files/dev.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(csv_file, test_size = 0.01):\n",
    "    train, test = train_test_split(csv_file, test_size = test_size)\n",
    "    train, val = train_test_split(train, test_size = test_size)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>fixed_inputs</th>\n",
       "      <th>mask_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168238</th>\n",
       "      <td>dfc4b5e71.jpg</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75370</th>\n",
       "      <td>643f953d3.jpg</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55541</th>\n",
       "      <td>4a06f9233.jpg</td>\n",
       "      <td>[357869 1 358636 3 359404 5 360171 7 360939 8 ...</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>04845f032.jpg</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183430</th>\n",
       "      <td>f3f4f6c7f.jpg</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "      <td>../../ml-data-training/ship_segmentation_data/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ImageId                                      EncodedPixels   \n",
       "168238  dfc4b5e71.jpg                                              [nan]  \\\n",
       "75370   643f953d3.jpg                                              [nan]   \n",
       "55541   4a06f9233.jpg  [357869 1 358636 3 359404 5 360171 7 360939 8 ...   \n",
       "3357    04845f032.jpg                                              [nan]   \n",
       "183430  f3f4f6c7f.jpg                                              [nan]   \n",
       "\n",
       "                                             fixed_inputs   \n",
       "168238  ../../ml-data-training/ship_segmentation_data/...  \\\n",
       "75370   ../../ml-data-training/ship_segmentation_data/...   \n",
       "55541   ../../ml-data-training/ship_segmentation_data/...   \n",
       "3357    ../../ml-data-training/ship_segmentation_data/...   \n",
       "183430  ../../ml-data-training/ship_segmentation_data/...   \n",
       "\n",
       "                                               mask_paths  \n",
       "168238  ../../ml-data-training/ship_segmentation_data/...  \n",
       "75370   ../../ml-data-training/ship_segmentation_data/...  \n",
       "55541   ../../ml-data-training/ship_segmentation_data/...  \n",
       "3357    ../../ml-data-training/ship_segmentation_data/...  \n",
       "183430  ../../ml-data-training/ship_segmentation_data/...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_imgs(img, mask, shape):\n",
    "    img = tf.io.read_file(img)\n",
    "    mask = tf.io.read_file(mask)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    mask = tf.image.decode_jpeg(mask, channels=1)\n",
    "    img = tf.image.resize(img, size=shape)\n",
    "    mask = tf.image.resize(mask, size=shape)\n",
    "    img = img / 255\n",
    "    mask = mask / 255\n",
    "    return img, mask\n",
    "\n",
    "def get_data(data, shape = (256, 256), shuffle = True, repeat = True, batch = True, batch_size = 32):\n",
    "    imgs, masks = data['fixed_inputs'].values.tolist(), data['mask_paths'].values.tolist()\n",
    "    shapes = [shape for x in range(len(imgs))]\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((imgs, masks, shapes))\n",
    "    tensor = tensor.cache()\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if shuffle:\n",
    "        tensor = tensor.shuffle(256 * REPLICAS)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        tensor = tensor.with_options(opt)\n",
    "    tensor = tensor.map(read_train_imgs)\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_data(train, shape = (256, 256), batch_size=64, shuffle=False, repeat=False)\n",
    "val_dataset = get_data(val, shape = (256, 256), batch_size=64, shuffle=False, repeat=False)\n",
    "test_dataset = get_data(test, shape = (256, 256), batch_size=64, shuffle=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    with strategy.scope():\n",
    "        model = sm.Unet(model_name)\n",
    "        model.compile(\n",
    "            'SGD',\n",
    "            loss = sm.losses.bce_jaccard_loss,\n",
    "            metrics = [sm.metrics.iou_score]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "#     model = get_model('inceptionv3')\n",
    "#     model.load_weights('../../ml-data-training/ship_seg_weights/segmentation/incep_baseline_bs_64_is_256/19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 7s 65ms/step - loss: 0.2183 - iou_score: 0.7612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21827682852745056, 0.7612173557281494]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2949/2949 [==============================] - 156s 53ms/step - loss: 0.2184 - iou_score: 0.7841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21842361986637115, 0.7840819954872131]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 64ms/step - loss: 0.2215 - iou_score: 0.7813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22150203585624695, 0.7812630534172058]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd5f438e8.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan(data):\n",
    "    if type(data[0]) == str:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['updated_col'] = train['EncodedPixels'].apply(check_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train = train[train['updated_col'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train = updated_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_dataset = get_data(updated_train, shape = (256, 256), batch_size=64, shuffle=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = get_model('inceptionv3')\n",
    "    model.load_weights('../../ml-data-training/ship_seg_weights/segmentation/incep_baseline_bs_64_is_256/19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 280ms/step\n"
     ]
    }
   ],
   "source": [
    "updated_train_pred = model.predict(updated_train_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = PIL.Image.fromarray((np.where(updated_train_pred[10].reshape(256, 256) > 0.5, 1, 0) * 255).astype(np.uint8))\n",
    "pred_mask = np.array(pred_mask).flatten()\n",
    "pred_mask = np.where(updated_train_pred[10].reshape(256, 256) > 0.5, 1, 0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_truth = PIL.Image.open(updated_train['mask_paths'].values.tolist()[10])\n",
    "g_truth = g_truth.resize((256, 256))\n",
    "# g_truth = np.array(g_truth).flatten() / 255\n",
    "g_truth = np.array(g_truth).flatten()\n",
    "test_check = np.where(np.logical_and(g_truth >= 0 , g_truth < 255), 0, g_truth)\n",
    "test_check = test_check / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum(np.logical_and(test_check == 1, pred_mask == 1))\n",
    "FP = sum(np.logical_and(test_check == 0, pred_mask == 1))\n",
    "FN = sum(np.logical_and(test_check == 1, pred_mask == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4864864864864865"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP / (TP + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "tensor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
