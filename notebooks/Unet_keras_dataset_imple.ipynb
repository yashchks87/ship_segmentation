{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"301a5d939c566d1487a049bb2554d09b592b18b1","trusted":true},"outputs":[],"source":["BATCH_SIZE = 4\n","EDGE_CROP = 16\n","NB_EPOCHS = 5\n","GAUSSIAN_NOISE = 0.1\n","UPSAMPLE_MODE = 'SIMPLE'\n","# downsampling inside the network\n","NET_SCALING = None\n","# downsampling in preprocessing\n","IMG_SCALING = (1, 1)\n","# number of validation images to use\n","VALID_IMG_COUNT = 400\n","# maximum number of steps_per_epoch in training\n","MAX_TRAIN_STEPS = 200\n","AUGMENT_BRIGHTNESS = False"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from skimage.io import imread\n","import matplotlib.pyplot as plt\n","import gc; gc.enable() # memory is tight\n","from sklearn.model_selection import train_test_split\n","import PIL\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["gpus = tf.config.list_physical_devices(\"GPU\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n"," PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n"," PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n"," PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n"," PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\n"," PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'),\n"," PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'),\n"," PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["gpus"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"]}],"source":["allowed_gpus = [6, 7]\n","gpus = tf.config.list_physical_devices(\"GPU\")\n","final_gpu_list = [gpus[x] for x in allowed_gpus]\n","tf.config.set_visible_devices(final_gpu_list, \"GPU\")\n","\n","strategy = tf.distribute.MirroredStrategy()\n","AUTO = tf.data.experimental.AUTOTUNE\n","REPLICAS = strategy.num_replicas_in_sync"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["csv_file = pd.read_csv('../../ml-data-training/ship_segmentation_data/train_ship_segmentations_v2.csv')\n","csv_file = csv_file.groupby('ImageId')['EncodedPixels'].apply(list).reset_index()\n","image_ids, pixels = csv_file['ImageId'].values.tolist(), csv_file['EncodedPixels'].values.tolist()\n","csv_file['fixed_inputs'] = csv_file['ImageId'].apply(lambda x: '../../ml-data-training/ship_segmentation_data/train_v2/' + x)\n","csv_file['mask_paths'] = csv_file['ImageId'].apply(lambda x: '../../ml-data-training/ship_segmentation_data/masks_v1/train/' + x.split('.')[0] + '.' + 'png')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ImageId</th>\n","      <th>EncodedPixels</th>\n","      <th>fixed_inputs</th>\n","      <th>mask_paths</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00003e153.jpg</td>\n","      <td>[nan]</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0001124c7.jpg</td>\n","      <td>[nan]</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000155de5.jpg</td>\n","      <td>[264661 17 265429 33 266197 33 266965 33 26773...</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>000194a2d.jpg</td>\n","      <td>[360486 1 361252 4 362019 5 362785 8 363552 10...</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001b1832.jpg</td>\n","      <td>[nan]</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","      <td>../../ml-data-training/ship_segmentation_data/...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         ImageId                                      EncodedPixels  \\\n","0  00003e153.jpg                                              [nan]   \n","1  0001124c7.jpg                                              [nan]   \n","2  000155de5.jpg  [264661 17 265429 33 266197 33 266965 33 26773...   \n","3  000194a2d.jpg  [360486 1 361252 4 362019 5 362785 8 363552 10...   \n","4  0001b1832.jpg                                              [nan]   \n","\n","                                        fixed_inputs  \\\n","0  ../../ml-data-training/ship_segmentation_data/...   \n","1  ../../ml-data-training/ship_segmentation_data/...   \n","2  ../../ml-data-training/ship_segmentation_data/...   \n","3  ../../ml-data-training/ship_segmentation_data/...   \n","4  ../../ml-data-training/ship_segmentation_data/...   \n","\n","                                          mask_paths  \n","0  ../../ml-data-training/ship_segmentation_data/...  \n","1  ../../ml-data-training/ship_segmentation_data/...  \n","2  ../../ml-data-training/ship_segmentation_data/...  \n","3  ../../ml-data-training/ship_segmentation_data/...  \n","4  ../../ml-data-training/ship_segmentation_data/...  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["csv_file.head()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def split_datasets(csv_file):\n","    train, test = train_test_split(csv_file, test_size=0.01, random_state=42)\n","    train, val = train_test_split(train, test_size=0.01, random_state=42)\n","    return train, val, test"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train, val, test = split_datasets(csv_file)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def read_train_imgs(img, mask, shape):\n","    img = tf.io.read_file(img)\n","    mask = tf.io.read_file(mask)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    mask = tf.image.decode_jpeg(mask, channels=1)\n","    img = tf.image.resize(img, size=shape)\n","    mask = tf.image.resize(mask, size=shape)\n","    img = img / 255\n","    mask = mask / 255\n","    return img, mask\n","\n","def get_data(data, shape = (256, 256), shuffle = True, repeat = True, batch = True, batch_size = 32):\n","    imgs, masks = data['fixed_inputs'].values.tolist(), data['mask_paths'].values.tolist()\n","    shapes = [shape for x in range(len(imgs))]\n","    tensor = tf.data.Dataset.from_tensor_slices((imgs, masks, shapes))\n","    tensor = tensor.cache()\n","    if repeat:\n","        tensor = tensor.repeat()\n","    if shuffle:\n","        tensor = tensor.shuffle(256 * REPLICAS)\n","        opt = tf.data.Options()\n","        opt.experimental_deterministic = False\n","        tensor = tensor.with_options(opt)\n","    tensor = tensor.map(read_train_imgs)\n","    if batch:\n","        tensor = tensor.batch(batch_size * REPLICAS)\n","    tensor = tensor.prefetch(AUTO)\n","    return tensor"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["train_dataset = get_data(train, shape = (64, 64), batch_size=32)\n","val_dataset = get_data(val, shape = (64, 64), batch_size=32)"]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"6181ac51577e5636995e38a9e29311cf47f513ca","trusted":true},"outputs":[],"source":["# def make_image_gen(in_df, batch_size = BATCH_SIZE):\n","#     input_imgs = in_df['fixed_inputs'].values.tolist()\n","#     mask_imgs = in_df['mask_paths'].values.tolist()\n","#     all_batches = [(input_imgs[x], mask_imgs[x]) for x in range(len(input_imgs))]\n","#     out_rgb = []\n","#     out_mask = []\n","#     while True:\n","#         np.random.shuffle(all_batches)\n","#         count = 0\n","#         for c_img_id, c_masks in all_batches:\n","#             rgb_path = c_img_id\n","#             c_img = imread(rgb_path)\n","#             c_mask = imread(c_masks).reshape(768, 768, 1)\n","#             if IMG_SCALING is not None:\n","#                 c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n","#                 c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n","#             out_rgb += [c_img]\n","#             out_mask += [c_mask]\n","#             if len(out_rgb)>=batch_size:\n","#                 yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n","#                 out_rgb, out_mask=[], []"]},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"1983738da75b031f2bec8ba36db01c095e7c5d59","trusted":true},"outputs":[],"source":["# train_gen = make_image_gen(train)\n","# train_x, train_y = next(train_gen)\n","# print('x', train_x.shape, train_x.min(), train_x.max())\n","# print('y', train_y.shape, train_y.min(), train_y.max())"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"b4396cd28ddd2e4c8076fcb165e9b61e3baeeeb7","trusted":true},"outputs":[],"source":["# fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n","# batch_rgb = montage_rgb(train_x)\n","# batch_seg = montage(train_y[:, :, :, 0])\n","# ax1.imshow(batch_rgb)\n","# ax1.set_title('Images')\n","# ax2.imshow(batch_seg)\n","# ax2.set_title('Segmentations')\n","# ax3.imshow(mark_boundaries(batch_rgb, \n","#                            batch_seg.astype(int)))\n","# ax3.set_title('Outlined Ships')\n","# fig.savefig('overview.png')"]},{"cell_type":"markdown","metadata":{"_uuid":"8f47639c987a10ebcb53e51f55aa8a11c98fa860"},"source":["# Make the Validation Set"]},{"cell_type":"code","execution_count":15,"metadata":{"_uuid":"30cb02a2a7103a9d66e90f701991199de1e5b73e","trusted":true},"outputs":[],"source":["# valid_x, valid_y = next(make_image_gen(val, 4))\n","# print(valid_x.shape, valid_y.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"a8f65e7942816fb75b687a549dc1d5cc48d00e21"},"source":["# Augment Data"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["# from keras.preprocessing.image import ImageDataGenerator\n","# # dg_args = dict(featurewise_center = False, \n","# #                   samplewise_center = False,\n","# #                   rotation_range = 15, \n","# #                   width_shift_range = 0.1, \n","# #                   height_shift_range = 0.1, \n","# #                   shear_range = 0.01,\n","# #                   zoom_range = [0.9, 1.25],  \n","# #                   horizontal_flip = True, \n","# #                   vertical_flip = True,\n","# #                   fill_mode = 'reflect',\n","# #                    data_format = 'channels_last')\n","# # # brightness can be problematic since it seems to change the labels differently from the images \n","# # if AUGMENT_BRIGHTNESS:\n","# #     dg_args[' brightness_range'] = [0.5, 1.5]\n","# # image_gen = ImageDataGenerator(**dg_args)\n","\n","# # if AUGMENT_BRIGHTNESS:\n","# #     dg_args.pop('brightness_range')\n","# # label_gen = ImageDataGenerator(**dg_args)\n","\n","# image_gen = ImageDataGenerator()\n","# label_gen = ImageDataGenerator()\n","\n","# def create_aug_gen(in_gen, seed = None):\n","#     # np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n","#     for in_x, in_y in in_gen:\n","#         # seed = np.random.choice(range(9999))\n","#         # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n","#         g_x = image_gen.flow(255*in_x, \n","#                              batch_size = in_x.shape[0], \n","#                              seed = seed, \n","#                              shuffle=True)\n","#         g_y = label_gen.flow(in_y, \n","#                              batch_size = in_x.shape[0], \n","#                              seed = seed, \n","#                              shuffle=True)\n","\n","#         yield next(g_x)/255.0, next(g_y)"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"6122ccb9e58bfac6fa5e11c86121e78d9e5151b1","trusted":true},"outputs":[],"source":["# cur_gen = create_aug_gen(train_gen)\n","# t_x, t_y = next(cur_gen)\n","# print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n","# print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n","# # only keep first 9 samples to examine in detail\n","# t_x = t_x[:9]\n","# t_y = t_y[:9]\n","# # fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n","# # ax1.imshow(montage_rgb(t_x), cmap='gray')\n","# # ax1.set_title('images')\n","# # ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\n","# # ax2.set_title('ships')"]},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"33300c4f03b6600da7b418f775d11d7ebf76a35a","trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["gc.collect()"]},{"cell_type":"markdown","metadata":{"_uuid":"ba08494eb9736ec3556b7c879143cdcdea89febf"},"source":["# Build a Model\n","Here we use a slight deviation on the U-Net standard"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["NET_SCALING"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["'SIMPLE'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["UPSAMPLE_MODE"]},{"cell_type":"code","execution_count":28,"metadata":{"_uuid":"2687377309d3cbbab1197f4eccd2b50ab996f5a6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," RGB_Input (InputLayer)         [(None, 128, 128, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," gaussian_noise_1 (GaussianNois  (None, 128, 128, 3)  0          ['RGB_Input[0][0]']              \n"," e)                                                                                               \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 128, 128, 3)  12         ['gaussian_noise_1[0][0]']       \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 128, 128, 8)  224         ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 128, 128, 8)  584         ['conv2d_19[0][0]']              \n","                                                                                                  \n"," max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 8)   0           ['conv2d_20[0][0]']              \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 64, 64, 16)   1168        ['max_pooling2d_4[0][0]']        \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 64, 64, 16)   2320        ['conv2d_21[0][0]']              \n","                                                                                                  \n"," max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 16)  0           ['conv2d_22[0][0]']              \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 32, 32, 32)   4640        ['max_pooling2d_5[0][0]']        \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 32, 32, 32)   9248        ['conv2d_23[0][0]']              \n","                                                                                                  \n"," max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 32)  0           ['conv2d_24[0][0]']              \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 16, 16, 64)   18496       ['max_pooling2d_6[0][0]']        \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_25[0][0]']              \n","                                                                                                  \n"," max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)    0           ['conv2d_26[0][0]']              \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 8, 8, 128)    73856       ['max_pooling2d_7[0][0]']        \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 8, 8, 128)    147584      ['conv2d_27[0][0]']              \n","                                                                                                  \n"," up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 128)  0          ['conv2d_28[0][0]']              \n","                                                                                                  \n"," concatenate_4 (Concatenate)    (None, 16, 16, 192)  0           ['up_sampling2d_4[0][0]',        \n","                                                                  'conv2d_26[0][0]']              \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 16, 16, 64)   110656      ['concatenate_4[0][0]']          \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_29[0][0]']              \n","                                                                                                  \n"," up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 64)  0           ['conv2d_30[0][0]']              \n","                                                                                                  \n"," concatenate_5 (Concatenate)    (None, 32, 32, 96)   0           ['up_sampling2d_5[0][0]',        \n","                                                                  'conv2d_24[0][0]']              \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 32, 32, 32)   27680       ['concatenate_5[0][0]']          \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 32, 32, 32)   9248        ['conv2d_31[0][0]']              \n","                                                                                                  \n"," up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 32)  0           ['conv2d_32[0][0]']              \n","                                                                                                  \n"," concatenate_6 (Concatenate)    (None, 64, 64, 48)   0           ['up_sampling2d_6[0][0]',        \n","                                                                  'conv2d_22[0][0]']              \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 64, 64, 16)   6928        ['concatenate_6[0][0]']          \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 64, 64, 16)   2320        ['conv2d_33[0][0]']              \n","                                                                                                  \n"," up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 16  0          ['conv2d_34[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_7 (Concatenate)    (None, 128, 128, 24  0           ['up_sampling2d_7[0][0]',        \n","                                )                                 'conv2d_20[0][0]']              \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 128, 128, 8)  1736        ['concatenate_7[0][0]']          \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 128, 128, 8)  584         ['conv2d_35[0][0]']              \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 128, 128, 1)  9           ['conv2d_36[0][0]']              \n","                                                                                                  \n"," cropping2d_1 (Cropping2D)      (None, 96, 96, 1)    0           ['conv2d_37[0][0]']              \n","                                                                                                  \n"," zero_padding2d_1 (ZeroPadding2  (None, 128, 128, 1)  0          ['cropping2d_1[0][0]']           \n"," D)                                                                                               \n","                                                                                                  \n","==================================================================================================\n","Total params: 491,149\n","Trainable params: 491,143\n","Non-trainable params: 6\n","__________________________________________________________________________________________________\n"]}],"source":["from keras import models, layers\n","# Build U-Net model\n","with strategy.scope():\n","    def upsample_conv(filters, kernel_size, strides, padding):\n","        return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n","    def upsample_simple(filters, kernel_size, strides, padding):\n","        return layers.UpSampling2D(strides)\n","\n","    if UPSAMPLE_MODE=='DECONV':\n","        upsample=upsample_conv\n","    else:\n","        upsample=upsample_simple\n","        \n","    # Please change below line shape accordingly 32 x 32 is not working and assuming anything lesser than that will not\n","    # work as well.\n","    input_img = layers.Input((128, 128, 3), name = 'RGB_Input')\n","    pp_in_layer = input_img\n","    if NET_SCALING is not None:\n","        pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n","        \n","    pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\n","    pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n","\n","    c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (pp_in_layer)\n","    c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n","    p1 = layers.MaxPooling2D((2, 2)) (c1)\n","\n","    c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n","    c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n","    p2 = layers.MaxPooling2D((2, 2)) (c2)\n","\n","    c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n","    c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n","    p3 = layers.MaxPooling2D((2, 2)) (c3)\n","\n","    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n","    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n","    p4 = layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n","\n","\n","    c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n","    c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n","\n","    u6 = upsample(64, (2, 2), strides=(2, 2), padding='same') (c5)\n","    u6 = layers.concatenate([u6, c4])\n","    c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n","    c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n","\n","    u7 = upsample(32, (2, 2), strides=(2, 2), padding='same') (c6)\n","    u7 = layers.concatenate([u7, c3])\n","    c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n","    c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n","\n","    u8 = upsample(16, (2, 2), strides=(2, 2), padding='same') (c7)\n","    u8 = layers.concatenate([u8, c2])\n","    c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n","    c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n","\n","    u9 = upsample(8, (2, 2), strides=(2, 2), padding='same') (c8)\n","    u9 = layers.concatenate([u9, c1], axis=3)\n","    c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n","    c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n","\n","    d = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n","    d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n","    d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\n","    if NET_SCALING is not None:\n","        d = layers.UpSampling2D(NET_SCALING)(d)\n","\n","    seg_model = models.Model(inputs=[input_img], outputs=[d])\n","    seg_model.summary()"]},{"cell_type":"code","execution_count":34,"metadata":{"_uuid":"1678069aa8013510264ba898291c6ae2dce88a76","trusted":true},"outputs":[],"source":["import keras.backend as K\n","from keras.optimizers import Adam\n","from keras.losses import binary_crossentropy\n","with strategy.scope():\n","    def dice_coef(y_true, y_pred, smooth=1):\n","        intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n","        union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n","        return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n","    def dice_p_bce(in_gt, in_pred):\n","        return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n","    def true_positive_rate(y_true, y_pred):\n","        return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n","    seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=keras.losses.BinaryCrossentropy(), metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"]},{"cell_type":"code","execution_count":35,"metadata":{"_uuid":"7282d18de3aff1cee12ff89b7d511a391702814f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"]}],"source":["from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n","weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n","\n","checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n","                             save_best_only=True, mode='max', save_weights_only = True)\n","\n","reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n","                                   patience=3, \n","                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n","early = EarlyStopping(monitor=\"val_dice_coef\", \n","                      mode=\"max\", \n","                      patience=15) # probably needs to be more patient, but kaggle time is limited\n","callbacks_list = [checkpoint, early, reduceLROnPlat]\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","737/737 [==============================] - 51s 61ms/step - loss: 0.0174 - dice_coef: 0.8016 - binary_accuracy: 0.9988 - true_positive_rate: 0.0000e+00 - val_loss: 0.0181 - val_dice_coef: 0.7906 - val_binary_accuracy: 0.9988 - val_true_positive_rate: 0.0000e+00\n","Epoch 2/50\n","737/737 [==============================] - 65s 89ms/step - loss: 0.0174 - dice_coef: 0.8016 - binary_accuracy: 0.9988 - true_positive_rate: 0.0000e+00 - val_loss: 0.0181 - val_dice_coef: 0.7906 - val_binary_accuracy: 0.9988 - val_true_positive_rate: 0.0000e+00\n","Epoch 3/50\n","737/737 [==============================] - 66s 90ms/step - loss: 0.0174 - dice_coef: 0.8016 - binary_accuracy: 0.9988 - true_positive_rate: 0.0000e+00 - val_loss: 0.0181 - val_dice_coef: 0.7906 - val_binary_accuracy: 0.9988 - val_true_positive_rate: 0.0000e+00\n","Epoch 4/50\n","737/737 [==============================] - 66s 90ms/step - loss: 0.0174 - dice_coef: 0.8016 - binary_accuracy: 0.9988 - true_positive_rate: 0.0000e+00 - val_loss: 0.0181 - val_dice_coef: 0.7906 - val_binary_accuracy: 0.9988 - val_true_positive_rate: 0.0000e+00\n","Epoch 5/50\n","737/737 [==============================] - 65s 89ms/step - loss: 0.0174 - dice_coef: 0.8016 - binary_accuracy: 0.9988 - true_positive_rate: 0.0000e+00 - val_loss: 0.0181 - val_dice_coef: 0.7906 - val_binary_accuracy: 0.9988 - val_true_positive_rate: 0.0000e+00\n","Epoch 6/50\n","737/737 [==============================] - 66s 90ms/step - loss: 0.0174 - dice_coef: 0.8017 - binary_accuracy: 0.9988 - true_positive_rate: 0.0000e+00 - val_loss: 0.0181 - val_dice_coef: 0.7906 - val_binary_accuracy: 0.9988 - val_true_positive_rate: 0.0000e+00\n","Epoch 7/50\n","626/737 [========================>.....] - ETA: 9s - loss: 0.0174 - dice_coef: 0.8021 - binary_accuracy: 0.9988 - true_positive_rate: 0.0000e+00"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m val_dataset \u001b[39m=\u001b[39m get_data(val, shape \u001b[39m=\u001b[39m (\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m), batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, repeat\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m strategy\u001b[39m.\u001b[39mscope():\n\u001b[0;32m----> 4\u001b[0m     model_hist \u001b[39m=\u001b[39m seg_model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      5\u001b[0m             train_dataset,\n\u001b[1;32m      6\u001b[0m             steps_per_epoch \u001b[39m=\u001b[39;49m \u001b[39mlen\u001b[39;49m(train) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m (\u001b[39m128\u001b[39;49m \u001b[39m*\u001b[39;49m REPLICAS),\n\u001b[1;32m      7\u001b[0m             epochs \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m             verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m             validation_data \u001b[39m=\u001b[39;49m val_dataset,\n\u001b[1;32m     10\u001b[0m         )\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_dataset = get_data(train, shape = (128, 128), batch_size=128)\n","val_dataset = get_data(val, shape = (128, 128), batch_size=128, repeat=False, shuffle=False)\n","with strategy.scope():\n","    model_hist = seg_model.fit(\n","            train_dataset,\n","            steps_per_epoch = len(train) // (128 * REPLICAS),\n","            epochs = 50,\n","            verbose = 1,\n","            validation_data = val_dataset,\n","        )"]},{"cell_type":"code","execution_count":168,"metadata":{"_uuid":"5b67d808c0b8c7e28bff41e6d3858ff6f09dd626","scrolled":false,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_355982/3169141231.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  loss_history = [seg_model.fit_generator(aug_gen,\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"," 21/200 [==>...........................] - ETA: 10:51 - loss: -0.0921 - dice_coef: 0.0929 - binary_accuracy: 0.6340 - true_positive_rate: nan"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[168], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m step_count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(MAX_TRAIN_STEPS, train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mBATCH_SIZE)\n\u001b[1;32m      2\u001b[0m aug_gen \u001b[39m=\u001b[39m create_aug_gen(make_image_gen(train))\n\u001b[0;32m----> 3\u001b[0m loss_history \u001b[39m=\u001b[39m [seg_model\u001b[39m.\u001b[39;49mfit_generator(aug_gen, \n\u001b[1;32m      4\u001b[0m                              steps_per_epoch\u001b[39m=\u001b[39;49mstep_count, \n\u001b[1;32m      5\u001b[0m                              epochs\u001b[39m=\u001b[39;49mNB_EPOCHS, \n\u001b[1;32m      6\u001b[0m                              validation_data\u001b[39m=\u001b[39;49m(valid_x, valid_y),\n\u001b[1;32m      7\u001b[0m                              callbacks\u001b[39m=\u001b[39;49mcallbacks_list,\n\u001b[1;32m      8\u001b[0m                             workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m# the generator is not very thread safe\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m                                        )]\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/keras/engine/training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2495\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \n\u001b[1;32m   2497\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2501\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2502\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2503\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2504\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2505\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2506\u001b[0m )\n\u001b[0;32m-> 2507\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2508\u001b[0m     generator,\n\u001b[1;32m   2509\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2510\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2511\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2512\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2513\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2514\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2515\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2516\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2517\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2518\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2519\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2520\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2521\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   2522\u001b[0m )\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/test_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["step_count = min(MAX_TRAIN_STEPS, train.shape[0]//BATCH_SIZE)\n","aug_gen = create_aug_gen(make_image_gen(train))\n","loss_history = [seg_model.fit_generator(aug_gen, \n","                             steps_per_epoch=step_count, \n","                             epochs=NB_EPOCHS, \n","                             validation_data=(valid_x, valid_y),\n","                             callbacks=callbacks_list,\n","                            workers=1 # the generator is not very thread safe\n","                                       )]"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a168c8b1af446b800f6129104906003ededd61c4","trusted":true},"outputs":[],"source":["def show_loss(loss_history):\n","    epich = np.cumsum(np.concatenate(\n","        [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n","    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(22, 10))\n","    _ = ax1.plot(epich,\n","                 np.concatenate([mh.history['loss'] for mh in loss_history]),\n","                 'b-',\n","                 epich, np.concatenate(\n","            [mh.history['val_loss'] for mh in loss_history]), 'r-')\n","    ax1.legend(['Training', 'Validation'])\n","    ax1.set_title('Loss')\n","\n","    _ = ax2.plot(epich, np.concatenate(\n","        [mh.history['true_positive_rate'] for mh in loss_history]), 'b-',\n","                     epich, np.concatenate(\n","            [mh.history['val_true_positive_rate'] for mh in loss_history]),\n","                     'r-')\n","    ax2.legend(['Training', 'Validation'])\n","    ax2.set_title('True Positive Rate\\n(Positive Accuracy)')\n","    \n","    _ = ax3.plot(epich, np.concatenate(\n","        [mh.history['binary_accuracy'] for mh in loss_history]), 'b-',\n","                     epich, np.concatenate(\n","            [mh.history['val_binary_accuracy'] for mh in loss_history]),\n","                     'r-')\n","    ax3.legend(['Training', 'Validation'])\n","    ax3.set_title('Binary Accuracy (%)')\n","    \n","    _ = ax4.plot(epich, np.concatenate(\n","        [mh.history['dice_coef'] for mh in loss_history]), 'b-',\n","                     epich, np.concatenate(\n","            [mh.history['val_dice_coef'] for mh in loss_history]),\n","                     'r-')\n","    ax4.legend(['Training', 'Validation'])\n","    ax4.set_title('DICE')\n","\n","show_loss(loss_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ce1167e9f09200f537e61f93f486168a13be1711","trusted":true},"outputs":[],"source":["seg_model.load_weights(weight_path)\n","seg_model.save('seg_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"275b411dc97a350aacaba46c8562efcf2658b1a7","trusted":true},"outputs":[],"source":["pred_y = seg_model.predict(valid_x)\n","print(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6a4fd2ca0cf47ba069a314356bf74c7b531c56ac","trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n","ax.hist(pred_y.ravel(), np.linspace(0, 1, 10))\n","ax.set_xlim(0, 1)\n","ax.set_yscale('log', nonposy='clip')"]},{"cell_type":"markdown","metadata":{"_uuid":"0018ab172d18936f8cc2c5df33d2f840dc16bf4f"},"source":["# Prepare Full Resolution Model\n","Here we account for the scaling so everything can happen in the model itself"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"17408f0ee8dc16149b8eff0447a1427ab3ed82ba","trusted":true},"outputs":[],"source":["if IMG_SCALING is not None:\n","    fullres_model = models.Sequential()\n","    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n","    fullres_model.add(seg_model)\n","    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n","else:\n","    fullres_model = seg_model\n","fullres_model.save('fullres_model.h5')"]},{"cell_type":"markdown","metadata":{"_uuid":"17edb177402ae51651692511827a7e9d60646533"},"source":["# Run the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4911811f267f9f3397a58902da9e75c6f261ad40","trusted":true},"outputs":[],"source":["test_paths = os.listdir(test_image_dir)\n","print(len(test_paths), 'test images found')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"73ef7b3b2a74bf64968c79b4005075d4f0e23143","trusted":true},"outputs":[],"source":["fig, m_axs = plt.subplots(20, 2, figsize = (10, 40))\n","[c_ax.axis('off') for c_ax in m_axs.flatten()]\n","for (ax1, ax2), c_img_name in zip(m_axs, test_paths):\n","    c_path = os.path.join(test_image_dir, c_img_name)\n","    c_img = imread(c_path)\n","    first_img = np.expand_dims(c_img, 0)/255.0\n","    first_seg = fullres_model.predict(first_img)\n","    ax1.imshow(first_img[0])\n","    ax1.set_title('Image')\n","    ax2.imshow(first_seg[0, :, :, 0], vmin = 0, vmax = 1)\n","    ax2.set_title('Prediction')\n","fig.savefig('test_predictions.png')"]},{"cell_type":"markdown","metadata":{"_uuid":"11a6c6615131ff8c317f95a5097b46565ef21121","collapsed":true,"trusted":true},"source":["# Submission\n","Since gneerating the submission takes a long time and quite a bit of memory we run it in a seperate kernel located at https://www.kaggle.com/kmader/from-trained-u-net-to-submission-part-2 \n","That kernel takes the model saved in this kernel and applies it to all the test data"]}],"metadata":{"kernelspec":{"display_name":"test_env","language":"python","name":"test_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":1}
